\documentclass[12pt, a4paper]{article}
\usepackage{graphicx} % Required for inserting images
\graphicspath{{./images}}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{mathtools}
\usepackage{fancyhdr}
\usepackage{cancel}
\usepackage[top=1in, left = 1in, right = 1in, bottom=1.2in]{geometry}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{float}

% Herlink setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

% For the code blocks
\definecolor{codegreen}{rgb}{0.03,0.5,0.03}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

% Code block setup
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    escapeinside = {(*}{*)}
}
\lstset{style=mystyle}

% My custom headers and margins 
\pagestyle{fancy}
\setlength{\headheight}{44pt}
\setlength{\headsep}{18pt}
\lhead{\includegraphics[scale = 0.2]{../../../bnw unit.png}}
\chead{\quad Data Science and Information Technologies Masterâ€™s
National and Kapodistrian University of Athens}
\rhead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}

% Start
\begin{document}

% Custom title page
\begin{titlepage}
    \centering
    {\huge \textbf{Homework 2}\par}
    \vspace{0.5cm}
    {\Large \textbf{Name:} Aris Podotas\par}
    \vspace{0.5cm}
    {\large \textbf{University:} National and Kapodistrian University of Athens\par}
    \vspace{0.5cm}
    {\large \textbf{Program:} Data Science and Informaion Technologies\par}
    \vspace{0.5cm}
    {\large \textbf{Specialization:} Bioinformatics - Biomedical Data\par}
    \vspace{0.5cm}
    {\large \textbf{Lesson:} Clustering Algorithms \par}
    \vspace{0.5cm}
    {\large \textbf{Date:} November 2024\par}
    \tableofcontents
\end{titlepage}

\section{Preface}

Since this exercise is for \textit{a more general analysis of data in a real scenario} rather than a typical concise homework, multiple tests and errors will be carried out. Ideas will be posited elaborated and discussed that are not necessarily correct, but the idea is to learn while completing this homework. Verbosity will be preferred over brevity.
\newline

The files added to the ones given within the original zip file are $main.m$ (the files implementing the solution).
\newline

The following is the beggining of the $main.m$ file that is common to the rest of the code block that follow
\begin{lstlisting}[label=lst:common, caption=The common global code in the $main.m$ file., language=Matlab]
x = load('data_country.mat');

[l, N] = size(x.Countrydata); % 167, 9
missing = zeros(l, N);

% Taking all the parameters of the distributions of the data we are given
total = [mean(x.Countrydata);
max(x.Countrydata);
min(x.Countrydata);
std(x.Countrydata);];

total
\end{lstlisting}

Regarding code-blocks, the $main.m$ file will not contain all blocks the way they are presented here. If segments are similar then one is likely to be the final version of the trials that were done. This should not be too problematic, for this homework has emphasis on analysis and it's process rather than a single code file that does everything. As a result of the specific code decisions just mentioned, most results will need to be shown here and not simply provided as supplementary. In any case the final version of the code will be provided and listed in this document at the end. Most of the redundant code that maps to a trial later changed will be within comments in the file.

\section{Feeling The Data} \label{Introduction}

\subsection{Overview} \label{stats}

The initial data overview before any other modifications to get a first impression was:

\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{lllllllllll}
            \toprule
            & Value & child mortality & exports & health & imports & income & inflation & life expectancy & total fertility & gdpp \\
            \midrule
            & min & 2.6 & 0.109 & 1.81 & 0.0659 & 609 & -4.21 & 32.1 & 1.15 & 231 \\
            & max & 208 & 200 & 17.9 & 174 & 125000 & 104 & 82.8 & 7.49 & 105000 \\
            & mean & 38.27 & 41.10 & 6.81 & 46.89 & 17144.68 & 7.78 & 70.55 & 2.94 & 12964.15 \\
            & stdev & 40.32 & 27.41 & 2.74 & 24.20 & 19278.06 & 10.57 & 8.89 & 1.51 & 18328.70 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Statistical representation of data: Country-data.csv}
    \label{tab:stats}
\end{table}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Child Mortality.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Exports.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Health.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Imports.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Income.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Inflation.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Life Expectancy.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Total Fertility.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/GDPP.png}} 
    \end{tabular}
    \caption{Histograms of Data (Country-data.csv). Bin numbers differ between images within the figure.}
    \label{fig:histograms}
\end{figure}

From Figure \ref{fig:histograms} we can see that the distributions of all the features differ from regular distributions (standard Gaussian). The Imports, Exports and Health of a country look closer to a gamma distribution than a standard Gaussian (or a Poisson distribution, certainly not a typical Gaussian).

One important aspect we can see in the graphs of the data is that some of the features of the data contain \textit{outliers}. This was already discussed in class that with this dataset the characterization of outliers is questionable. In any case a median based clustering algorithm will be considered in the trials below.

None of the factors of the data are discreet values. All features feature continuous data. This is not to say that data fields do not seem discreet or are not usually discreet, but it is to say that the data given can be interpreted in a continuous format for all features, however not all values can necessarily be interpreted as discreet. It is for this reason that all values will be used as if they were continuous.

\textbf{Note: }Figure \ref{fig:histograms} has 9 sub images that each contain a histogram with a differing number of bins. In order to compare our data visually, the way we do previously and further in the report, we should consider presenting the data with the same number of bins in total. More so these histograms are of non-normalized data, and we should consider re doing the histograms with the same number of bins after the normalization if any.
\newline

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Child mortality.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Exports.png} } &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Health.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Imports.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Income.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Inflation.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Life expectancy.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Total fertility.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Histogram of GDPP.png}} 
    \end{tabular}
    \caption{Histograms of Data (data\_country.mat). Bin numbers do not differ between images within the figure.}
    \label{fig:mathistograms}
\end{figure}

This second iteration of the data might seem redundant, as $data\_country.mat$ and $County-data.csv$ contain the same data. This re-iteration is because the equivalent (Figure \ref{fig:mathistograms}) produces the un-normalized data histograms with \textit{equal numbers of bins}. Notice that there are also more bins. There is a way to find the optimal number of bins for a graph, this is outside the scope of this homework; however, we will demonstrate one out of curiosity.
\newline

The code that generated Figure \ref{fig:mathistograms}:
\newline

\begin{lstlisting}[language=Matlab, caption=Iterations that create the histograms., label=lst:regular]
% Histograms
for k=1:N
    % Find missing data
    if find(x.Countrydata(:,k) == 0)
    else
        missing(:, k) = 1;
    end
    figure(k)
    % I use the same number of bins ofr all the graphs to be consistent
    hist(x.Countrydata(:,k), 20)
    if k==1
        title('Histogram of Child mortality')
        saveas(k, 'Histogram of Child mortality.png')
    elseif k==2
        title('Histogram of Exports') 
        saveas(k, 'Histogram of Exports.png')
    elseif k==3
        title('Histogram of Health')
        saveas(k, 'Histogram of Health.png')
    elseif k==4
        title('Histogram of Imports')
        saveas(k, 'Histogram of Imports.png')
    elseif k==5 
        title('Histogram of Income')
        saveas(k, 'Histogram of Income.png')
    elseif k==6
        title('Histogram of Inflation')
        saveas(k, 'Histogram of Inflation.png')
    elseif k==7
        title('Histogram of Life expectancy')
        saveas(k, 'Histogram of Life expectancy.png')
    elseif k==8
        title('Histogram of Total fertility')
        saveas(k, 'Histogram of Total fertility.png')
    elseif k==9
        title('Histogram of GDPP')
        saveas(k, 'Histogram of GDPP.png')
    end
end
\end{lstlisting}

Sturge's rule for the optimal number of bins: \[\text{The number of bins $b$ should be } b = \lceil log_2(N) + 1\rceil, \quad \text{Sturges (1926)} \] Using the Sturge's rule:
\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Child mortality (Sturges Rule).png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Exports (Sturges Rule).png} } &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Health (Sturges Rule).png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Imports (Sturges Rule).png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Income (Sturges Rule).png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Inflation (Sturges Rule).png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Life expectancy (Sturges Rule).png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Histogram of Total fertility (Sturges Rule).png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Histogram of GDPP (Sturges Rule).png}} 
    \end{tabular}
    \caption{Histograms of Data (data\_country.mat). Bin numbers do not differ between images within the figure.}
    \label{fig:sturges}
\end{figure}

In Figure \ref{fig:sturges}, all images have the same number of bins. There are fewer bins than before with the user-defined random number (20) (Figure \ref{fig:mathistograms}). The aforementioned outliers (putative) are less prominent in this visualization of the data. We can say that previously the visualization of the data led to false positives for outliers. These histograms are also less variable than previously.
\newline

The code that generated Figure \ref{fig:sturges}:
\newline

\begin{lstlisting}[language=Matlab, caption=Iterations that create the Sturges rule histograms., label=lst:sturges]
% Once for the optimal bins number
for k=1:N
    % Find missing data
    if find(x.Countrydata(:,k) == 0)
    else
        missing(:, k) = 1;
    end
    figure(k)
    % Using the Sturges Rule
    optimal = ceil(log2(N)+1);
    % I use the same number of bins ofr all the graphs to be consistent
    hist(x.Countrydata(:,k), optimal)
    if k==1
        title('Histogram of Child mortality (Sturges Rule)')
        saveas(k, 'Histogram of Child mortality (Sturges Rule).png')
    elseif k==2
        title('Histogram of Exports (Sturges Rule)') 
        saveas(k, 'Histogram of Exports (Sturges Rule).png')
    elseif k==3
        title('Histogram of Health (Sturges Rule)')
        saveas(k, 'Histogram of Health (Sturges Rule).png')
    elseif k==4
        title('Histogram of Imports (Sturges Rule)')
        saveas(k, 'Histogram of Imports (Sturges Rule).png')
    elseif k==5 
        title('Histogram of Income (Sturges Rule)')
        saveas(k, 'Histogram of Income (Sturges Rule).png')
    elseif k==6
        title('Histogram of Inflation (Sturges Rule)')
        saveas(k, 'Histogram of Inflation (Sturges Rule).png')
    elseif k==7
        title('Histogram of Life expectancy (Sturges Rule)')
        saveas(k, 'Histogram of Life expectancy (Sturges Rule).png')
    elseif k==8
        title('Histogram of Total fertility (Sturges Rule)')
        saveas(k, 'Histogram of Total fertility (Sturges Rule).png')
    elseif k==9
        title('Histogram of GDPP (Sturges Rule)')
        saveas(k, 'Histogram of GDPP (Sturges Rule).png')
    end
end
\end{lstlisting}

We can imagine a more efficient way of naming and saving all the histograms, however this change would have no impact on the efficiency of the compilation of the code and the final output. In order to avoid needlessly complex iterations this simple switch like statement will suffice.

\subsection{Missing Data}

There is no missing data withing the files $County-data.csv$, $data\_country.mat$. This is seen via the following:
\newline

\begin{lstlisting}[language=Matlab, label=lst:missing, caption=Code that find if missing data exists.]
for k=1:9
    % Find missing data
    if any(find(x.Countrydata(:,k) == 0)) || any(find(isnan(x.Countrydata(:,k)))) || any(find(x.Countrydata(:,k) == missing))
    else
        missing(:, k) = 1;
    end
end
if find(missing == 0)
    find(missing == 0)
end
\end{lstlisting}

This was actually visible in the previous listings (listing \ref{lst:regular} and \ref{lst:sturges}).
\newline

\textbf{Note:} The $missing$ variable in the above listing is initialized in the global code in the $main.m$ file form the preface \ref{lst:common}.
\newline

Listing \ref{lst:missing} outputs:
\newline

\begin{lstlisting}[language=Matlab, label=lst:missing output, caption=Missing data matrix.]
% No output
\end{lstlisting}

At this point one assumption is that the cross correlation should happen after the normalization steps. We should take the cross correlations before and after a normalization to check.

\subsection{Cross Correlation}

The previous Statistical overview (Section \ref{Introduction} page \pageref{Introduction}, Table \ref{tab:stats}, Figure \ref{fig:histograms}) has given us some visual insight to consider for our data. For instance we can see that the Life expectancy does not have a distribution that follows any of the other distributions. To be as rigorous as possible we should consider the features in pairs of 2. This is to split the problem to multiple smaller regression tasks.
\newline

To do this the code we will use is:
\begin{lstlisting}[language=Matlab, label=lst:Cross term, caption=Code that calculates the cross correlations of the data features before and after normalization.]
% We are going to consider all the pairs of data and vidualize them
prior_relations = corrcoef(x.Countrydata);

% Normalization (linear)
normalization = x;
for i=1:N
    for j=1:l
        normalization.Countrydata(j, i) = (x.Countrydata(j,i) - mean(x.Countrydata(:,i)))/(std(x.Countrydata(:, i)));
    end
end

posterior_relations = corrcoef(normalization.Countrydata);
\end{lstlisting}

\subsubsection{Before Normalization}

\begin{lstlisting}[language=Matlab, label=lst:prior, caption=The cross correlation output before normalization.]
prior_relations =

    1.0000   -0.3181   -0.2004   -0.1272   -0.5243    0.2883   -0.8867    0.8485   -0.4830
   -0.3181    1.0000   -0.1144    0.7374    0.5168   -0.1073    0.3163   -0.3200    0.4187
   -0.2004   -0.1144    1.0000    0.0957    0.1296   -0.2554    0.2107   -0.1967    0.3460
   -0.1272    0.7374    0.0957    1.0000    0.1224   -0.2470    0.0544   -0.1590    0.1155
   -0.5243    0.5168    0.1296    0.1224    1.0000   -0.1478    0.6120   -0.5018    0.8956
    0.2883   -0.1073   -0.2554   -0.2470   -0.1478    1.0000   -0.2397    0.3169   -0.2216
   -0.8867    0.3163    0.2107    0.0544    0.6120   -0.2397    1.0000   -0.7609    0.6001
    0.8485   -0.3200   -0.1967   -0.1590   -0.5018    0.3169   -0.7609    1.0000   -0.4549
   -0.4830    0.4187    0.3460    0.1155    0.8956   -0.2216    0.6001   -0.4549    1.0000
\end{lstlisting}

\subsubsection{After Normalization}

\begin{lstlisting}[language=Matlab, label=lst:posterior, caption=The cross correlation output after normalization.]
posterior_realtions =

    1.0000   -0.3181   -0.2004   -0.1272   -0.5243    0.2883   -0.8867    0.8485   -0.4830
   -0.3181    1.0000   -0.1144    0.7374    0.5168   -0.1073    0.3163   -0.3200    0.4187
   -0.2004   -0.1144    1.0000    0.0957    0.1296   -0.2554    0.2107   -0.1967    0.3460
   -0.1272    0.7374    0.0957    1.0000    0.1224   -0.2470    0.0544   -0.1590    0.1155
   -0.5243    0.5168    0.1296    0.1224    1.0000   -0.1478    0.6120   -0.5018    0.8956
    0.2883   -0.1073   -0.2554   -0.2470   -0.1478    1.0000   -0.2397    0.3169   -0.2216
   -0.8867    0.3163    0.2107    0.0544    0.6120   -0.2397    1.0000   -0.7609    0.6001
    0.8485   -0.3200   -0.1967   -0.1590   -0.5018    0.3169   -0.7609    1.0000   -0.4549
   -0.4830    0.4187    0.3460    0.1155    0.8956   -0.2216    0.6001   -0.4549    1.0000    
\end{lstlisting}

\subsubsection{Final Cross correlation}

We can now notice that the cross-correlation in both cases (when we have not normalized, when we have normalized) does not differ. We can continue with any of the cross-correlation terms as a result, but a good question would be why this is the case.
\newline

The help page of the $corrcoef()$ function in Matlab yields the result that the computation is:
\[
\rho(A,B) = \frac{1}{N-1}\sum_{i=1}^{N}{\left(\frac{A_i-\mu_A}{\sigma_A}\right)\left(\frac{B_i-\mu_B}{\sigma_B}\right)}
\]
which is the Pearson correlation coefficient. The final output is:
\[
R=\left[\begin{matrix}
    1 & \rho(A,B) \\
    \rho(B,A) & 1
\end{matrix}\right] 
\]
Expanded to as many terms as necessary. To see why the results of the normalization were the same we should consider the following, which is listed on the Matlab help page for $corcoef()$:
\newline

\begin{lstlisting}[language=Matlab, caption=The cross correlation output after normalization.]
R = corrcoef(A) % returns the matrix of correlation coefficients for A, where the columns of A represent random variables and the rows represent observations.
\end{lstlisting}

This essentially means that when we wrote $corrcoef(x.Countrydata)$ each of the 9 feature vectors were considered in pairs where:
\begin{equation*}
    \begin{split}
        & A = x.Countrydata(:,k) \\
        & B = x.Countrydata(:,k+1) \\
        & k=1,2,\dots,N-1 \\
        &  \rho(A,B) = \frac{1}{N-1}\sum_{i=1}^{N}{\left(\frac{A_i-\mu_A}{\sigma_A}\right)\left(\frac{B_i-\mu_B}{\sigma_B}\right)} \iff\\
        & \frac{1}{N-1} \sum_{i=1}^{N}{\left(\frac{A_iB_i -\mu_BA_i -\mu_AB_i +\mu_A\mu_B}{\sigma_A\sigma_B}\right)}\\
    \end{split}
\end{equation*}
Let us consider just one $A_i, B_i$
\begin{equation*}
    \begin{split}
        & \frac{1}{N-1} \frac{A_1B_1 -\mu_BA_1 -\mu_AB_1 +\mu_A\mu_B}{\sigma_A\sigma_B} \\
        & \text{Expanding the mean and the variance} \\
        & \frac{1}{N-1} \frac{A_1B_1 -\frac{\sum_{i=1}^{N}{B_i}}{N}A_1 -\frac{\sum_{i=1}^{N}{A_i}}{N}B_1 +\frac{\sum_{i=1}^{N}{A_i}}{N}\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}} \\
    \end{split}
\end{equation*}
When we normalized the data manually, we defined a new $A_i, \mu_A, \sigma_A$ and similarly for $B$.
\begin{equation*}
    \begin{split}
        & A'=\frac{A-\mu_A}{\sigma_A}=\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}} \\
        & B'=\frac{B-\mu_B}{\sigma_B}=\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}} \\
        & \mu_A' = \frac{\sum_{i=1}^{N}{A_i'}}{N} = \frac{\sum_{i=1}^{N}{\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}}}}{N} \\
        & \mu_B' = \frac{\sum_{i=1}^{N}{B_i'}}{N} = \frac{\sum_{i=1}^{N}{\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}}}}{N} \\
        & \sigma_A' = \sqrt{\frac{\sum_{i=1}^{N}{\left(A_i'-\frac{\sum_{i=1}^{N}{A_i'}}{N}\right)^2}}{N}} = \sqrt{\frac{\sum_{i=1}^{N}{\left(\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}}-\frac{\sum_{i=1}^{N}{\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}}}}{N}\right)^2}}{N}} \\
        & \sigma_B' = \sqrt{\frac{\sum_{i=1}^{N}{\left(B_i'-\frac{\sum_{i=1}^{N}{B_i'}}{N}\right)^2}}{N}} = \sqrt{\frac{\sum_{i=1}^{N}{\left(\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}}-\frac{\sum_{i=1}^{N}{\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}}}}{N}\right)^2}}{N}} \\
    \end{split}
\end{equation*}
Then if we substitute into the equation we ended up at for the cross correlation.
\begin{equation*}
    \begin{split}
        & \frac{1}{N-1} \frac{A'_1B'_1 -\mu_B'A'_1 -\mu_A'B'_1 +\mu_A'\mu_B'}{\sigma_A'\sigma_B'} \iff \\
        & \frac{1}{N-1} \frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}} \frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}} \\
        & -\frac{\sum_{i=1}^{N}{\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}}}}{N} \frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}} \\
        & -\frac{\sum_{i=1}^{N}{\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}}}}{N}\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}} \\
        & +\frac{\sum_{i=1}^{N}{\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}}}}{N} \frac{\sum_{i=1}^{N}{\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}}}}{N} \\
        & \frac{1}{\sqrt{\frac{\sum_{i=1}^{N}{\left(\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}}-\frac{\sum_{i=1}^{N}{\frac{A-\frac{\sum_{i=1}^{N}{A_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(A_i-\frac{\sum_{i=1}^{N}{A_i}}{N}\right)^2}}{N}}}}}{N}\right)^2}}{N}}  } \\
        & \frac{1}{\sqrt{\frac{\sum_{i=1}^{N}{\left(\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}}-\frac{\sum_{i=1}^{N}{\frac{B-\frac{\sum_{i=1}^{N}{B_i}}{N}}{\sqrt{\frac{\sum_{i=1}^{N}{\left(B_i-\frac{\sum_{i=1}^{N}{B_i}}{N}\right)^2}}{N}}}}}{N}\right)^2}}{N}}}
    \end{split}
\end{equation*}
Doing all of this we realize that solving for $A$, $B$ and substituting is easier thus:
\begin{equation*}
    \begin{split}
        & A =  A'\sigma_A + \mu_A\\
        & B =  B'\sigma_B + \mu_B\\
        & \frac{1}{N-1} \frac{A'(\sigma_A + \mu_A)B'(\sigma_B + \mu_B) -\mu_BA'(\sigma_A + \mu_A) -\mu_AB'(\sigma_B + \mu_B) +\mu_A\mu_B}{\sigma_A\sigma_B} \iff \\
        & \frac{1}{N+1} \frac{(A'\sigma_A + \mu_AA')(B'\sigma_B + \mu_BB') -\mu_BA'\sigma_A - \mu_A\mu_BA' -\mu_AB'\sigma_B - \mu_AB'\mu_B + \mu_A\mu_B}{\sigma_A\sigma_B} \iff \\
        & \frac{A'\sigma_AB'\sigma_B + A'\sigma_A\mu_BB' + \mu_AA'B'\sigma_B + \mu_AA'\mu_BB' -\mu_BA'\sigma_A - \mu_A\mu_BA' -\mu_AB'\sigma_B - \mu_AB'\mu_B + \mu_A\mu_B}{(N+1)\sigma_A\sigma_B} \\
        & \iff (\frac{1}{N+1}) (\frac{A'\cancel{\sigma_A}B'\cancel{\sigma_B}}{\cancel{\sigma_A\sigma_B}} + \frac{A'\cancel{\sigma_A}\mu_BB'}{\cancel{\sigma_A}\sigma_B}+ \frac{\mu_AA'B'\cancel{\sigma_B}}{\sigma_A\cancel{\sigma_B}} + \frac{\mu_AA'\mu_BB'}{\sigma_A\sigma_B}-\frac{\mu_BA'\cancel{\sigma_A}}{\cancel{\sigma_A}\sigma_B} - \frac{\mu_A\mu_BA'}{\sigma_A\sigma_B} -\frac{\mu_AB'\cancel{\sigma_B}}{\sigma_A\cancel{\sigma_B}} \\
        & - \frac{\mu_AB'\mu_B}{\sigma_A\sigma_B} + \frac{\mu_A\mu_B}{\sigma_A\sigma_B}) \iff \\
        & \iff (\frac{1}{N+1}) (A' B'  + \frac{A' \mu_BB'}{ \sigma_B}+ \frac{\mu_AA'B' }{\sigma_A } + \frac{\mu_AA'\mu_BB'}{\sigma_A\sigma_B}-\frac{\mu_BA' }{ \sigma_B} - \frac{\mu_A\mu_BA'}{\sigma_A\sigma_B} -\frac{\mu_AB' }{\sigma_A } \\
        & - \frac{\mu_AB'\mu_B}{\sigma_A\sigma_B} + \frac{\mu_A\mu_B}{\sigma_A\sigma_B}) \iff \\
        & \frac{1}{N-1}\left(\frac{A'\sigma_A + \mu_A -\mu_A}{\sigma_A}\right)\left(\frac{B'\sigma_B + \mu_B -\mu_B}{\sigma_B}\right) = \frac{1}{N+1}A'B' = \frac{1}{N-1}\left(\frac{A-\mu_A}{\sigma_A}\right)\left(\frac{B -\mu_B}{\sigma_B}\right)\\
    \end{split}
\end{equation*}
In conclusion, it makes no difference to normalize before the $corrcoef()$ function.

\subsubsection{Visual Overview}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 1, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Child mortality - all other features.}
    \label{fig:Scatter 1, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 2, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Exports - all other features.}
    \label{fig:Scatter 2, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 3, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Health - all other features.}
    \label{fig:Scatter 3, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 4, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Imports - all other features.}
    \label{fig:Scatter 4, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 5, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Income - all other features.}
    \label{fig:Scatter 5, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 6, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Inflation - all other features.}
    \label{fig:Scatter 6, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 7, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Life Expectancy - all other features.}
    \label{fig:Scatter 7, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 8, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for Total Fertility - all other features.}
    \label{fig:Scatter 8, x}
\end{figure}

\begin{figure}[H]
    \begin{tabular}{ccc}
        \subfloat[Child Mortality]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 1.png}} &
        \subfloat[Exports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 2.png}} &
        \subfloat[Health]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 3.png}} \\
        \subfloat[Imports]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 4.png}} &
        \subfloat[Income]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 5.png}} &
        \subfloat[Inflation]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 6.png}} \\ 
        \subfloat[Life Expectancy]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 7.png}} &
        \subfloat[Total Fertility]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 8.png}} &
        \subfloat[GDPP]{\includegraphics[width = 0.3\textwidth]{images/Correlation between features 9, 9.png}} 
    \end{tabular}
    \caption{Scatter plots of cross correlations for GDPP - all other features.}
    \label{fig:Scatter 9, x}
\end{figure}

These graphs were made with the following code:
\newline

\begin{lstlisting}[language=Matlab, label=lst:scatters, caption=Production of scatter plots for pairs of features.]
% Making a figure for each of the pairs
for i=1:N
   for j=1:N
       figure(i*9+j)
       scatter(x.Countrydata(:,i), x.Countrydata(:,j))
       title(sprintf('Correlation between features %.0f, %.0f', i, j)) 
       saveas(i*9+j, sprintf('Correlation between features %.0f, %.0f.png', i, j))
   end
end
\end{lstlisting}

This code could have been a little more efficient, omitting plots that have already been added in a previous graph but since the $corrcoef()$ function outputs a matrix with all the pairs, all pairs were kept. These scatter plots don't add any information that is not visible in the correlation coefficient however, they are more readable. Be cautious when relating one of the scatter plots to the outputs of the $corrcoef()$ function for they are not one to one. This code will be commented out, if you want to output the results simply un-comment those lines.

\section{Feature Selection/Transformation}

In order to do this we will reference the cross-correlation from before heavily to tell what features are required and what transformation the data should be put through. In particular values of pairs of features that are cross-correlated highly should be simplified to a single feature. This is because if two features are highly correlated then we should be able to use one to represent both of them. To this aim we look to the $corrcoef()$ outputs and pick a cutoff that if a pairing is over in relation we decide that one of the two of those features should be removed.

\subsection{Cutoffs}

\subsubsection{Attempt 1}

The implementation of the above idea is as follows:

\begin{lstlisting}[language=Matlab, label=lst:feat, caption=The code that selects features to keep.]
% Deciding what features to use since some of them are evidently related very much
function output = selection(data, coef)
    [~, N] = size(data.Countrydata);
    for i=N:-1:1
        for j=N:-1:1
            % Making sure that we remove really realted features
            if find(1 > coef(i,j) && coef(i,j) > 0.8)
                data.Countrydata(:,i) = [];
            % Making sure that features that are related inversly are removed
            elseif find(coef(i,j) < -0.8)
                data.Countrydata(:,i) = [];
            end
        end
    end
    output = data;
end

% Running the function for all sets of data

selection(ncopy, posterior_relations);
\end{lstlisting}

\textbf{Note: }It does not matter which variables with the data we use, or which table of correlation coefficients since both of the tables are identical.
\newline

\textbf{Note: }We do two loops that got inversely (from $9$ to $1$) because if we do operations that change the size of the data structure in increasing order then we will introduce the possibility of indexing into memory not belonging to the array.
\newline

We notice that the above code produces a list (the same list updated) with only 3 features. This seems a little weird considering that we see in the table of the cross correlation that only 3 pairing fulfill the criteria to be removed. Upon closer inspection the above function will check the whole cross correlation table and find these 3 points twice. We should consider only the one triangle of the table.

\subsubsection{Attempt 2}

The way this will be implemented is that for any matrix
\begin{equation*}
    \begin{split}    
        A = \left[\begin{matrix}
            a_{11} & a_{12} & \cdots & a_{1j} \\
            a_{21} & a_{22} & \cdots & a_{2j} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{i1} & a_{i2} & \cdots & a_{ij} \\
        \end{matrix}\right]
    \end{split}
\end{equation*}
In order to get the elements belonging to the one triangle over the diagonal we have to notice that the column number is always greater or equal to the row number we are on.
The diagonal is defined by elements that satisfy:
\begin{equation*}
    \begin{split}    
        i = j
    \end{split}
\end{equation*}
Points over this will belong to the upper triangle and will satisfy
\begin{equation*}
    \begin{split}    
        i \leq j
    \end{split}
\end{equation*}
Implementation:
\begin{lstlisting}[language=Matlab, label=lst:feat2, caption=The code that selects features to keep (attempt 2).]
% Deciding what features to use since some of them are evidently related very much
function output = selection(data, coef)
    [~, N] = size(data.Countrydata);
    for i=N:-1:1
        for j=N:-1:1
            if i<=j
                % Making sure that we remove really realted features
                if find(1 > coef(i,j) && coef(i,j) > 0.8)
                    data.Countrydata(:,i) = [];
                % Making sure that features that are related inversly are removed
                elseif find(coef(i,j) < -0.8)
                    data.Countrydata(:,j) = [];
                end
            end
        end
    end
    output = data;
end

% Running the function for all sets of data

ncopy = selection(ncopy, posterior_relations);
xcopy = selection(x, posterior_relations);
\end{lstlisting}
The only difference is an if statement that checks if the criteria above is true and the index of the second if statement (because otherwise we would remove index 1 twice and that does not map to the feature we want to remove). This now outputs the same variable with 6 columns.
\newline

The data removed is one feature from the following relations
\begin{center}
\[
\begin{array}{c|rrrrrrrrr}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
1 &  1.0000 & -0.3181 & -0.2004 & -0.1272 & -0.5243 &  0.2883 & -0.8867 &  0.8485 & -0.4830 \\
2 & -0.3181 &  1.0000 & -0.1144 &  0.7374 &  0.5168 & -0.1073 &  0.3163 & -0.3200 &  0.4187 \\
3 & -0.2004 & -0.1144 &  1.0000 &  0.0957 &  0.1296 & -0.2554 &  0.2107 & -0.1967 &  0.3460 \\
4 & -0.1272 &  0.7374 &  0.0957 &  1.0000 &  0.1224 & -0.2470 &  0.0544 & -0.1590 &  0.1155 \\
5 & -0.5243 &  0.5168 &  0.1296 &  0.1224 &  1.0000 & -0.1478 &  0.6120 & -0.5018 &  0.8956 \\
6 &  0.2883 & -0.1073 & -0.2554 & -0.2470 & -0.1478 &  1.0000 & -0.2397 &  0.3169 & -0.2216 \\
7 & -0.8867 &  0.3163 &  0.2107 &  0.0544 &  0.6120 & -0.2397 &  1.0000 & -0.7609 &  0.6001 \\
8 &  0.8485 & -0.3200 & -0.1967 & -0.1590 & -0.5018 &  0.3169 & -0.7609 &  1.0000 & -0.4549 \\
9 & -0.4830 &  0.4187 &  0.3460 &  0.1155 &  0.8956 & -0.2216 &  0.6001 & -0.4549 &  1.0000 \\
\end{array}
\]
\end{center}
are coordinates
\begin{equation*}
    \begin{split}
        \left[\begin{matrix}
            1 & 7 \\
            1 & 8 \\
            5 & 9 \\
        \end{matrix}\right]
    \end{split}
\end{equation*}
These coordinates relate to features Child Mortality, Life Expectancy, Total Fertility, Income, GDPP. To be completely clear one from (Child Mortality, Life Expectancy, Total Fertility) and (Income, GDPP) will be chosen (The choice is done randomly since both are equivalent).

\subsection{Transformations}

One transformation has already been done on a copy of the data in the variable $normalization$.
\newline

A reminder of the transformation:

\begin{equation*}
    A' = \frac{A-\mu_A}{\sigma_A}
\end{equation*}

There is general curiosity what this transformation of the data will yield when clustering. For this reason the un-normalized variables persist in the codebase so that they too can be analyzed to see the effect of the normalization.
\newline

There is another normalization to consider

\begin{equation*}
    \begin{split}
        & min \leq x \leq max \iff \\
        & 0 \leq x-min \leq max - min \iff \\
        & 0 \leq \frac{x-min}{max-min} \leq 1 \\
    \end{split}
\end{equation*}

Before applying this we should remember that computationally floating point numbers have a level of resolution that might cause some data loss upon conversion. This will need to be elaborated on later.

\begin{lstlisting}[language=Matlab, label=lst:datatransform, caption=The code that implements the data transfromation in the range $0$ to $1$.]
% Data transform

function out = transform(data, stats)
    % stats is the total variable, that has the max in position 2 and the min in position 3
    data.Countrydata = (data.Countrydata - min(stats(3,:)))/(max(stats(2,:))-min(stats(3,:)));
    out = data;
end

ncopy = transform(ncopy, total);
\end{lstlisting}

Our data has similar minimum values for all features but large differences in the maximum values of different features.
\begin{table}[H]
    \centering
    \caption{Statistical values of each feature}
    \begin{tabularx}{\textwidth}{lXXXXXXXXX}
        \toprule
        Value & Child Mor. & Exports & Health & Imports & Income & Inflation & Life Ex. & Total Fert. & GDPP \\ 
        \midrule
        Mean & 38.27 & 41.11 & 6.82 & 46 & 17144 & 7.78 & 70 & 2.95 & 12964 \\ 
        Max & 208 & 200 & 17.9 & 174.00 & 125000 & 104 & 82 & 7.49 & 105000 \\ 
        Min & 2.6 & 0.11 & 1.81 & 0.07 & 609 & -4.21 & 32.1 & 1.15 & 231 \\ 
        Std & 40.33 & 27.41 & 2.75 & 24.21 & 19278 & 10.57 & 8.89 & 1.51 & 18328 \\ 
        \bottomrule
    \end{tabularx}
\end{table}
Because of this our normalization can keep a minimum value of $0$. The maximum value differs orders of magnitude between features, for this reason the maximum normalization range will be logarithmic. These changes will be separate from the previous normalization considered for the cross correlation.
\newline

The way this will be implemented:
\begin{equation*}
    \begin{split}
        & min \leq x \leq max \iff \\
        & 0 \leq x-min \leq max - min \iff \\
        & 0 \leq \frac{x-min}{max-min} \leq 1 \iff \\
        & 0 \times d \leq \frac{x-min}{max-min} \times d \leq d \iff \\
        & 0 \leq \frac{x-min}{max-min} \times d \leq d \\
        & \text{We opt for }d \text{ to be } \log(\max(\text{data})) \\ 
    \end{split}
\end{equation*}

\begin{lstlisting}[language=Matlab, label=lst:logtransform, caption=The code that implements the logarithmic transfromation in the range $0$ to $log(max(data))$.]
function out = logtransform(data, stats)
    % stats is the total variable, that has the max in position 2 and the min in position 3
    data.Countrydata = ((log(max(stats(2,:))))*(data.Countrydata - min(stats(3,:))))/(max(stats(2,:))-min(stats(3,:)));
    out = data;
end

xcopy = logtransform(xcopy, total);
\end{lstlisting}

\section{Selection of the Clustering Algorithms}

\subsection{Assumptions}
First, because of the state of the histograms (\ref{fig:histograms}) that seem to indicate that some values might be outliers, the assumption is that a clustering algorithm utilizing the median rather than the mean will perform better.

Second, because of the gradient with which features of countries change geographically (and ecologically) algorithms that do not do \textit{hard} clustering will represent the countries better. More on this point the characteristics that we assume as hard clusters for countries to be within (such as the EU, continent) are actually arbitrary. For instance clustering Greece and Norway within the same cluster and interpreting this as a commonality due to them being in the same continent is disingenuous.

Third, precisely because the interpretation of what the cluster consists of more than one correct answer given exists (more than one interpretation is correct, the actual answer is a single one).

\subsection{Conclusion}

In conclusion all clustering algorithms will be tested but a consideration of their weaknesses should be done.

\section{Execution of the Algorithms}

\subsection{Representation}

Due to the dimensionality of the data it is hard to visualize the results of the clustering. One solution is to split each set of 3 features into their own 3d plot and present 3 3d (or 2 depending on if its the filtered data) plots. One question would then be what sub sets of 3 would be picked for each of these graphs. In the case of the data that has not been filtered then maybe the decision might matter but for the filtered data any set of 3 should be representative. That being said not all pairs will be visually distinguishable in the plot so picking features that have similar ranges of values would be optimal.
\newline

All initial $\theta$ values were made by a function that generates them within the convex hull of the data randomly.

\subsection{Number of clusters}

To determine the number of clusters we will plot the values of the cost function after running the k-means algorithm for different amounts of clusters for all our copies of the data and their transformations.

% First Subfigure
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x optimal.png}
    \caption{Cost functions of x for increasing numbers of clusters up to 10}
    \label{fig:x-optimal}
\end{figure}

% Second Subfigure
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy optimal.png}
    \caption{Cost functions of xcopy for increasing numbers of clusters up to 10}
    \label{fig:xcopy-optimal}
\end{figure}

% Third Subfigure
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/normalization optimal.png}
    \caption{Cost functions of normalization for increasing numbers of clusters up to 10}
    \label{fig:normalization-optimal}
\end{figure}

% Fourth Subfigure
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/ncopy optimal.png}
    \caption{Cost functions of ncopy for increasing numbers of clusters up to 10}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{lstlisting}[language=Matlab, label=lst:optimals, caption=The code that implements the visualization of the cost function with changing numbers of clusters. In order to replicate the above graphs the 4 calls of the function at the end should be done one by one]
% Implementing a function to find the number of clusters
function amount(sheet)
    costs = ones(1,10);
    for j = 2:10
        theta = generate(sheet, j);
        [theta,bel,J] = k_means(sheet.Countrydata', theta');
        costs(:,j-1) = J;
    end
    plot(1:10, costs)
    xlabel('Number of clusters')
    ylabel('Cost function')
end

% Dont run all of these at once, they should be done one at a time
amount(x);
amount(xcopy);
amount(normalization);
amount(ncopy);
\end{lstlisting}

The results given by the $ncopy$ and $normalization$ parameters are alarming and are indicative of some fault in the normalization done on the data. It would seem that the z index normalization does not suit our dataset. These will not be considered any further.
\newline

Based on these results we can see that the optimal value of clusters is $4$ or $3$. A four clustering seems more sensible since in both graphs the marginal slope change happens after four clusters are considered for both datasets, while the 3 clustering has slightly different results for both and the slope after the 3rd cluster is still negative to a satisfying degree.
\newline

% it removed income it remoced child mort then total fert
A Note for all the following figures. When the output contains only two images the first set of 3 features refers to (Exports, Health, Imports), the second to (Inflation, Life Expectancy, GDPP). Otherwise the first set of 3 is (Child Mortality, Exports, Health), the second (Imports, Income, Inflation) and the final (Life Expectancy, Total Fertility, GDPP).
\newline

Each clustering algorithm will have the output produced by 3 variables in the codebase. $x$, $xcopy$, $simplified$ differ in that $x$ is the original un-changed un-normalized un-filtered data,  $xcopy$ is the original data log transformed and filtered, $simplified$ is the original data minmax transformed in the range $[0,1]$ and filtered. It is recommended to not run all the variables at once but rather to un-comment the calls of the final function for each of them one at a time.
\newline

\subsubsection{Hard k-means}

For $x$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k means first 3.png}
    \caption{K means 4-clustering of $x$ (1/3). x = Child Mortality, y = Exports, z = Health}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k means second 3.png}
    \caption{K means 4-clustering of $x$ (2/3). x = Imports, y = Income, z = Inflation}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k means final 3.png}
    \caption{K means 4-clustering of $x$ (3/3). x = Life Expectancy, y = Total Fertility, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $xcopy$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy k means first 3.png}
    \caption{K means 4-clustering of $xcopy$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy k means second 3.png}
    \caption{K means 4-clustering of $xcopy$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $simplified$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified k means first 3.png}
    \caption{K means 4-clustering of $simplified$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified k means second 3.png}
    \caption{K means 4-clustering of $simplified$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

\subsubsection{Hard k-medians}

For $x$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k medians first 3.png}
    \caption{k medians 4-clustering of $x$ (1/3). x = Child Mortality, y = Exports, z = Health}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k medians second 3.png}
    \caption{k medians 4-clustering of $x$ (2/3). x = Imports, y = Income, z = Inflation}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k medians final 3.png}
    \caption{k medians 4-clustering of $x$ (3/3). x = Life Expectancy, y = Total Fertility, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $xcopy$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy k medians first 3.png}
    \caption{k medians 4-clustering of $xcopy$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy k medians second 3.png}
    \caption{k medians 4-clustering of $xcopy$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $simplified$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified k medians first 3.png}
    \caption{k medians 4-clustering of $simplified$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified k medians second 3.png}
    \caption{k medians 4-clustering of $simplified$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

\subsubsection{Hard k-medoids}

For $x$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k medoids first 3.png}
    \caption{k medoids 4-clustering of $x$ (1/3). x = Child Mortality, y = Exports, z = Health}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k medoids second 3.png}
    \caption{k medoids 4-clustering of $x$ (2/3). x = Imports, y = Income, z = Inflation}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x k medoids final 3.png}
    \caption{k medoids 4-clustering of $x$ (3/3). x = Life Expectancy, y = Total Fertility, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $xcopy$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy k medoids first 3.png}
    \caption{k medoids 4-clustering of $xcopy$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy k medoids second 3.png}
    \caption{k medoids 4-clustering of $xcopy$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $simplified$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified k medoids first 3.png}
    \caption{k medoids 4-clustering of $simplified$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified k medoids second 3.png}
    \caption{k medoids 4-clustering of $simplified$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

\subsubsection{Possibilistic c-means}

For $x$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x c means first 3.png}
    \caption{c means 4-clustering of $x$ (1/3). x = Child Mortality, y = Exports, z = Health}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x c means second 3.png}
    \caption{c means 4-clustering of $x$ (2/3). x = Imports, y = Income, z = Inflation}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/x c means final 3.png}
    \caption{c means 4-clustering of $x$ (3/3). x = Life Expectancy, y = Total Fertility, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $xcopy$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy c means first 3.png}
    \caption{c means 4-clustering of $xcopy$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/xcopy c means second 3.png}
    \caption{c means 4-clustering of $xcopy$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

For $simplified$:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified c means first 3.png}
    \caption{c means 4-clustering of $simplified$ (1/2). x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/simplified c means second 3.png}
    \caption{c means 4-clustering of $simplified$ (2/2). x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

Keep in mind that these algorithms (some) are dependent on the initialization positions of the $\theta$'s. We tried to represent some of the "Best" runs.

\subsection{Assumption validation}

It would seem that the normalization of the data did not output better results in the clustering phase. It is because of this that we will consider the results of the clustering on the $x$ variable more so than the rest (it could just be that we got better initialization of the clusters for this variable).

\subsubsection{First assumption}
It would seem that the first assumption was correct for the k-medoids (hard) has output the best results for all variables.
\newline

\textbf{Note: }Evident by the results for the variables $xcopy, simplified$ for hard k-medoids.

\subsubsection{Second assumption}
It would seem that the possibilistic algorithm has output better than two of the three hard clustering algorithms.

\subsubsection{Third assumption}
Because of the dependence on the initial $\theta$ values and the difference in the clustering that would have been produced had we drawn our conclusions on the results of the possibilistic (compared to the medoids) algorithm this assumption holds true. In the characterization of the clusters if we had picked different algorithms the clusters themselves would have been characterized by different values of features. 

\section{Characterization of the Clusters}

\subsection{Deciding on the algorithm}

Due to reasons previously mentioned (and potentially luck regarding the cluster initialization), the clustering algorithm with the most representative results is the hard k-medoids. Notice that for the data the outliers mentioned in the start of the report appear to exist in the $x$ clustering but not in any of the following variables. Still because some runs show clusters consisting of 3 data points and the distribution of the data, it is safe to call some of our data points as outliers.

\subsection{Deciding on the data variable}

The transformed variables have output worse results than $x$ in the clustering of any of the algorithms outside the hard k-medoids. However $x$ still contains the features whose correlation is high (essentially this means that if we plotted those 3 features in one of our plots we would see a slightly deviated line forming). If we chose a variable other than $x$ we lose the ability to reference other algorithms, if we choose $x$ however we include redundant data in the final view. One solution would be to implement a filtered $x$ without any transformation on the data. If however, we look closely at the results for all variables with the chosen algorithm we can see that they have all produced the same clustering (a different indexed cluster represents all the same data). It is for this reason that we will choose to represent the data sing the $simplified$ variable that is equivalent to the $xcopy$ variable for this clustering.

\subsection{Final thoughts}

We have produced a $4$ clustering of the data, and based on the results of the algorithm picked this seems like a valid number of clusters. Let us add the data labels to see what exactly was clustered. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/medoids labels first.png}
    \caption{k-medoids with labels first set of 3 features. x = Exports, y = Health, z = Imports}
    \label{fig:ncopy-optimal}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/medoids labeled.png}
    \caption{k-medoids with labels second set of 3 features. x = Inflation, y = Life Expectancy, z = GDPP}
    \label{fig:ncopy-optimal}
\end{figure}

Geographic characteristics have little to do with the clusters, island and land bound countries can be (and have been) clustered. Counties of different climate and different ecology can be (and have been) clustered together. Countries in different geopolitical unions can be (and have been) clustered together.
\newline

It would appear that the clusters do not follow pre-conceived notions of cluster of countries (in that continental boundaries, unions ... do not cluster the data). Some countries perceived as outliers simply define a cluster of their own, a sensible cluster.

\subsubsection{The first cluster}
The first cluster (red) containing Malta, Singapore and Luxembourg that are all characterized by low spending on healthcare per person, high imports and exports, low (the lowest) GDPP, low inflation and high life expectancy. On these axis these 3 countries (red cluster) are quite similar to eachother and quite distinct from all other clusters.

\subsubsection{The second cluster}
The second (yellow) cluster is characterized by the second best average import and export rate, generally no trend in inflation metrics but a high life expectancy with a slightly better GDPP. The distinction of this cluster is sensible but much lower than the first cluster.

\subsubsection{The third cluster}
The third (green) cluster is characterized by the best GDPP of all clusters (likely due to the influence of Nigeria), a high degree of imports or a high degree of exports (the averages lie quite near to the previous cluster but the distribution is more deviated), practically no trend on healthcare spending, an average (dispersed) life expectancy compared to other clusters and practically no trend for inflation (the highest variance on this axis). The how distinct this cluster is to the second cluster is higher than the fourth cluster and the distinction with the fourth cluster is quite questionable. Potential local minima might have been reached by the algorithm especially when defining the difference with the fourth and final cluster.

\subsubsection{The final cluster}
Finally the last cluster (dark blue) is characterized by the third best GDPP with a relatively low variance, the worst life expectancy, practically no trend for inflation, practically no trend on healthcare spending per capita thought the mean is the highest (likely due to America), the worst export and import rate (with a relatively Gaussian distribution skewed to higher values). Questions about the distinctness of this cluster have already been brought up when refering to the third cluster.
\newline

Upon looking at the graphical clustering representation these statistica values are visible between the clusters.
\newline

In total the spending on healthcare per person seems to have had little effect on the clustering.
\newline

\subsection{Final code}

To re-iterate some of the lines shown are commented out, either because the lines are failed trials reported upon or because they are not to all be run together but one at a time because they use the same figure.
\newline

\textbf{Note: }Some of the segments of code shown above are not the same because above we show pieces of code that are far away in the actual file in one listing.
\newline

The final $main.m$ file:

\begin{lstlisting}[language=Matlab, label=lst:final, caption=The entire code as it was upon completion.]
x = load('data_country.mat');
[l, N] = size(x.Countrydata); % 167, 9

% Normalization (linear)
normalization = x;
for i=1:N
    for j=1:l
        normalization.Countrydata(j, i) = (x.Countrydata(j,i) - mean(x.Countrydata(:,i)))/(std(x.Countrydata(:, i)));
    end
end

simplified = x;

missing = zeros(l, N);

% Taking all the parameters of the distributions of the data we are given
total = [mean(x.Countrydata);
         max(x.Countrydata);
         min(x.Countrydata);
         std(x.Countrydata);];

% Once for the optimal bins number
for k=1:N
    % Find missing data
    if any(find(x.Countrydata(:,k) == 0)) || any(find(isnan(x.Countrydata(:,k)))) || any(find(x.Countrydata(:,k) == missing))
    else
        % Updating the matrix of boolians
        missing(:, k) = 1;
    end
    % 1 will be a non missing field
    figure(k)
    % Using the Sturges Rule
    % Otherwise the bins used were 20
    optimal = ceil(log2(N)+1);
    % I use the same number of bins ofr all the graphs to be consistent
    histogram(x.Countrydata(:,k), optimal)
    if k==1
        title('Histogram of Child mortality (Sturges Rule)')
        % saveas(k, 'Histogram of Child mortality (Sturges Rule).png')
    elseif k==2
        title('Histogram of Exports (Sturges Rule)') 
        % saveas(k, 'Histogram of Exports (Sturges Rule).png')
    elseif k==3
        title('Histogram of Health (Sturges Rule)')
        % saveas(k, 'Histogram of Health (Sturges Rule).png')
    elseif k==4
        title('Histogram of Imports (Sturges Rule)')
        % saveas(k, 'Histogram of Imports (Sturges Rule).png')
    elseif k==5 
        title('Histogram of Income (Sturges Rule)')
        % saveas(k, 'Histogram of Income (Sturges Rule).png')
    elseif k==6
        title('Histogram of Inflation (Sturges Rule)')
        % saveas(k, 'Histogram of Inflation (Sturges Rule).png')
    elseif k==7
        title('Histogram of Life expectancy (Sturges Rule)')
        % saveas(k, 'Histogram of Life expectancy (Sturges Rule).png')
    elseif k==8
        title('Histogram of Total fertility (Sturges Rule)')
        % saveas(k, 'Histogram of Total fertility (Sturges Rule).png')
    elseif k==9
        title('Histogram of GDPP (Sturges Rule)')
        % saveas(k, 'Histogram of GDPP (Sturges Rule).png')
    end
    clear optimal
end

% Showing if we have missing data or not
if find(missing == 0)
    problem = 'There was missing data found'
end

clear missing

% We are going to consider all the pairs of data and vidualize them
prior_relations = corrcoef(x.Countrydata);
posterior_relations = corrcoef(normalization.Countrydata);
% the prior and posterior end up the same
clear prior_relations

% Making a figure for each of the pairs
for i=1:N
   for j=1:N
       figure(i*9+j)
       scatter(x.Countrydata(:,i), x.Countrydata(:,j))
       title(sprintf('Correlation between features %.0f, %.0f', i, j)) 
       % saveas(i*9+j, sprintf('Correlation between features %.0f, %.0f.png', i, j))
   end
end

% We will keep the total features and the selected ones seperatly. Applying the following on both sets of data.

% Deciding what features to use since some of them are evidently related very much
function output = selection(data, coef)
    [~, N] = size(data.Countrydata);
    % These loops go backwards because we run into memory erors otherwise from acessing memory that does not belong to the matrix
    for i=N:-1:1
        for j=N:-1:1
            if i<=j
                % Making sure that we remove really realted features
                if find(1 > coef(i,j) && coef(i,j) > 0.8)
                    data.Countrydata(:,i) = [];
                % Making sure that features that are related inversly are removed
                elseif find(coef(i,j) < -0.8)
                    data.Countrydata(:,j) = [];
                end
            end
        end
    end
    output = data;
end

% Running the function for all sets of data

% Making copies
% This variable will be aparent later (log transform)
xcopy = selection(x, posterior_relations);
ncopy = selection(normalization, posterior_relations);
simplified = selection(simplified, posterior_relations);

% Data transform

function out = transform(data, stats)
    % stats is the total variable, that has the max in position 2 and the min in position 3
    data.Countrydata = (data.Countrydata - min(stats(3,:)))/(max(stats(2,:))-min(stats(3,:)));
    out = data;
end

function out = logtransform(data, stats)
    % stats is the total variable, that has the max in position 2 and the min in position 3
    data.Countrydata = ((log(max(stats(2,:))))*(data.Countrydata - min(stats(3,:))))/(max(stats(2,:))-min(stats(3,:)));
    out = data;
end

% Regular transform of x
simplified = transform(simplified, total);
% log transform of x
xcopy = logtransform(xcopy, total);
% transform of normalization
ncopy = transform(ncopy, total);

% Clustering algorithm loops
% There is a general issue on how to represent the data that is this hight in dimensions
% The dimensionality issue will be discussed in the report
% Reminder
% x has the original data
% Normalization has the z score normalized data
% ncopy is the copy of the normalized data that has pruned features
% xcopy is the copy of the original data that has pruned features
% They all have both fields of the original struct

% Implementing a function to look for theta values
function theta = generate(sheet, number)
    % This is going to need to return values within the convex hull
    % Example theta that could be output
    % theta = [0, 20, 0, 20;
    %          0, 0, 20, 20;
    %          1, 5, 20, 20;
    %          0, 0, 20, 20;
    %          0, 0, 20, 20;
    %          0, 0, 20, 20;
    %          0, 0, 20, 20;
    %          0, 0, 20, 20;
    %          0, 0, 20, 20;];
    [~,N] = size(sheet.Countrydata);
    data = [max(sheet.Countrydata);
            min(sheet.Countrydata);];
    theta = ones(number,N);
    for i=1:number
        for j=1:N
            % Normalized random initial value in the range [min, max]
            theta(i,j) = (max(data(1)))*(randn()) + min(data(2));
        end
    end
end

% Implementing a function to find the number of clusters
function amount(sheet, seed)
    figure(1000 + seed)
    costs = ones(1,10);
    for j = 2:10
        theta = generate(sheet, j);
        [theta,bel,J] = k_means(sheet.Countrydata', theta');
        costs(:,j-1) = J;
    end
    plot(1:10, costs)
    xlabel('Number of clusters')
    ylabel('Cost function')
end

% Number of clusters
amount(x, 4);
% All the below are problematic figures mentioned in the report
% amount(xcopy, 62);
% amount(normalization, 102);
% amount(ncopy, 1038);

function cluster(sheet, clusters)
    % Clusters refers to the number of clusters
    % Implementing a function to do each iteration of the clustering for each alrgorithm so that the iterations throught the data is simple
    % Remember that the previous final figure was figure 90
    [l, N] = size(sheet.Countrydata); % Keep in mind that this N is variable
    % Looping to try different clusterings
    theta = generate(sheet, clusters);
    % k-means
    % Note we need to transpose since our data vectors are on rows
    [theta,bel,J] = k_means(sheet.Countrydata', theta');
    [N, m] = size(theta);
    for i=1:(N/3)
        figure(90 + i), hold on
        figure(90 + i), grid on
        for j=1:m
            figure(90 + i), plot3(theta(i,j), theta(i + 1,j), theta(i + 2,j), 'k+')
        end
        figure(90 + i), plot3(sheet.Countrydata(bel==1,i), sheet.Countrydata(bel==1, i+ 1), sheet.Countrydata(bel==1,i+2), 'ro')
        figure(90 + i), plot3(sheet.Countrydata(bel==2,i), sheet.Countrydata(bel==2, i+ 1), sheet.Countrydata(bel==2,i+2), 'g*')
        figure(90 + i), plot3(sheet.Countrydata(bel==3,i), sheet.Countrydata(bel==3, i+ 1), sheet.Countrydata(bel==3,i+2), 'b.')
        figure(90 + i), plot3(sheet.Countrydata(bel==4,i), sheet.Countrydata(bel==4, i+ 1), sheet.Countrydata(bel==4,i+2), 'ys')
        for k = 1:l
            text(sheet.Countrydata(k,i),sheet.Countrydata(k,i+1) ,sheet.Countrydata(k,i+2) , sheet.country(k), 'FontSize', 8, 'HorizontalAlignment', 'left')
        end
        if i == 1
            title('k-means first 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        elseif i==2
            title('k-means second 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        else
            title('k-means final 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        end
    end

    % k-medoids
    [bel,cost,theta,a] = k_medoids(sheet.Countrydata', clusters, 72);
    [N, m] = size(theta);
    for i=1:(N/3)
        figure(90 + i + N/3), hold on
        figure(90 + i + N/3), grid on
        for j=1:m
            figure(90 + i + N/3), plot3(theta(i,j), theta(i + 1,j), theta(i + 2,j), 'k+')
        end
        figure(90 + i + N/3), plot3(sheet.Countrydata(bel==1,i), sheet.Countrydata(bel==1, i+ 1), sheet.Countrydata(bel==1,i+2), 'ro')
        figure(90 + i + N/3), plot3(sheet.Countrydata(bel==2,i), sheet.Countrydata(bel==2, i+ 1), sheet.Countrydata(bel==2,i+2), 'g*')
        figure(90 + i + N/3), plot3(sheet.Countrydata(bel==3,i), sheet.Countrydata(bel==3, i+ 1), sheet.Countrydata(bel==3,i+2), 'b.')
        figure(90 + i + N/3), plot3(sheet.Countrydata(bel==4,i), sheet.Countrydata(bel==4, i+ 1), sheet.Countrydata(bel==4,i+2), 'ys')
        for k = 1:l
            text(sheet.Countrydata(k,i),sheet.Countrydata(k,i+1) ,sheet.Countrydata(k,i+2) , sheet.country(k), 'FontSize', 8, 'HorizontalAlignment', 'left')
        end
        if i == 1
            title('k-medoids first 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        elseif i==2
            title('k-medoids second 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        else
            title('k-medoids final 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        end
    end

    % k-medians
    theta = generate(sheet, clusters);
    [theta,bel,J] = k_medians(sheet.Countrydata', theta');
    [N, m] = size(theta);
    for i=1:(N/3)
        figure(90 + i + 2*N/3), hold on
        figure(90 + i + 2*N/3), grid on
        for j=1:m
            figure(90 + i + 2*N/3), plot3(theta(i,j), theta(i + 1,j), theta(i + 2,j), 'k+')
        end
        figure(90 + i + 2*N/3), plot3(sheet.Countrydata(bel==1,i), sheet.Countrydata(bel==1, i+ 1), sheet.Countrydata(bel==1,i+2), 'ro')
        figure(90 + i + 2*N/3), plot3(sheet.Countrydata(bel==2,i), sheet.Countrydata(bel==2, i+ 1), sheet.Countrydata(bel==2,i+2), 'g*')
        figure(90 + i + 2*N/3), plot3(sheet.Countrydata(bel==3,i), sheet.Countrydata(bel==3, i+ 1), sheet.Countrydata(bel==3,i+2), 'b.')
        figure(90 + i + 2*N/3), plot3(sheet.Countrydata(bel==4,i), sheet.Countrydata(bel==4, i+ 1), sheet.Countrydata(bel==4,i+2), 'ys')
        for k = 1:l
            text(sheet.Countrydata(k,i),sheet.Countrydata(k,i+1) ,sheet.Countrydata(k,i+2) , sheet.country(k), 'FontSize', 8, 'HorizontalAlignment', 'left')
        end
        if i == 1
            title('k-medians first 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        elseif i==2
            title('k-medians second 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        else
            title('k-medians final 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        end
    end

    % Possibilistic
    eta = ones(1, clusters);
    [U, theta] = possibi(sheet.Countrydata', clusters, eta,1,73,1,0.01);
    [N, m] = size(theta);
    for i=1:(N/3)
        figure(90 + i + 3*N/3), hold on
        figure(90 + i + 3*N/3), grid on
        for j=1:m
            figure(90 + i + 3*N/3), plot3(theta(i,j), theta(i + 1,j), theta(i + 2,j), 'k+')
        end
        figure(90 + i + 3*N/3), plot3(sheet.Countrydata(bel==1,i), sheet.Countrydata(bel==1, i+ 1), sheet.Countrydata(bel==1,i+2), 'ro')
        figure(90 + i + 3*N/3), plot3(sheet.Countrydata(bel==2,i), sheet.Countrydata(bel==2, i+ 1), sheet.Countrydata(bel==2,i+2), 'g*')
        figure(90 + i + 3*N/3), plot3(sheet.Countrydata(bel==3,i), sheet.Countrydata(bel==3, i+ 1), sheet.Countrydata(bel==3,i+2), 'b.')
        figure(90 + i + 3*N/3), plot3(sheet.Countrydata(bel==4,i), sheet.Countrydata(bel==4, i+ 1), sheet.Countrydata(bel==4,i+2), 'ys')
        for k = 1:l
            text(sheet.Countrydata(k,i),sheet.Countrydata(k,i+1) ,sheet.Countrydata(k,i+2) , sheet.country(k), 'FontSize', 8, 'HorizontalAlignment', 'left')
        end
        if i == 1
            title('Possibilistic c-means first 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        elseif i==2
            title('Possibilistic c-means second 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        else
            title('Possibilistic clustering algorithm final 3 features')
            xlabel('x')
            ylabel('y')
            zlabel('z')
        end
    end

end

% cluster(xcopy, 4);
% final2 = cluster(ncopy);
% cluster(simplified, 4);
% cluster(simplified, 3);
% cluster(simplified, 2);
cluster(x, 4);
% supplement2 = cluster(normalization);
\end{lstlisting}
Notice that we re initialize the $\theta$'s between clustering algorithms.

\section{Re-evaluation}

After the lecture done on the 12/12/2024 a discussion occured that said that representations of higher dimensional data actually take away aspects of the data themselves (the features). Due to this a re-evaluation of the previous resutls has been added. It would seem wrong to remove the previous results and write over them the new evalution since we would like to contrast the results with previous.
\newline

Previously, cluster 1 (red) contained three countries out of $167$ total. This cluster is sensible because of its separation to the others however a cluster with three countries in total is not so sensible. One of the main aspects to re-evaluate will be the bounds of this cluster.
\newline

The only aspect of the previous analysis that need re-evaluation is the selection of the clustering algorithms and everything affected by this choice. To a degree the clustering algorithms that have a dependance on the initialization of the clusters have worse results, due to the positions we initialize in so let us re-write the function that generates the $\theta$ values upon initialization.

\begin{lstlisting}
    lstlisting
\end{lstlisting}

One of the assumptions made was that the possibilistic algorithms should output more realistic results because of the continuity of featreus between countries, thus we will focus on more attempts for the possibilistic algorithms. Actually the previous visualizations of the results of the possibilistic algorithms were incorrect because the coloration of the points uses the outputs of the previously ran algorithms. To re-examine the results of these algorithms we will need to use the variable that hold the degree of beloning of all countries to each cluster.

\section{Citations}

Sturges, H. A. (1926). The Choice of a Class Interval. Journal of the American Statistical Association, 21(153), 65â€“66. https://doi.org/10.1080/01621459.1926.10502161
\newline

Fisher, R.A. (1958). Statistical Methods for Research Workers, 13th Ed., Hafner. 
\newline

Kendall, M.G. (1979). The Advanced Theory of Statistics, 4th Ed., Macmillan.
\newline

Press, W.H., Teukolsky, S.A., Vetterling, W.T., and Flannery, B.P. (1992) Numerical Recipes in C, 2nd Ed., Cambridge University Press.

\end{document}
